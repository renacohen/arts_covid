---
title: "Model"
author: "Rena Cohen"
date: "11/24/2020"
output: html_document
---

```{r}

library(tidyverse)

afta_covid_2 <- readRDS("~/Desktop/GOV 50/final_project/milestone_4/processed_data/afta_covid_2.RDS")

small <- afta_covid_2 %>%
  filter(budget == "100,000 to  249,999") %>%
  filter(lost_revenue_total > 1) %>%
  mutate(laid_off_total = laid_off_artists_amt + laid_off_staff_amt) %>%
  filter(date < "2020-06-01") %>%
  filter(lost_revenue_total < 600000) %>%
  # Filtering to get rid of some crazy outliers 
  filter(lost_attendees < quantile(lost_attendees, 0.995, na.rm = T)) %>%
filter(lost_revenue_total < quantile(lost_revenue_total, 0.995, na.rm = T)) 


library(rstanarm)
library(tidymodels)


fit_1 <- lm(sqrt(lost_revenue_total)~ lost_attendees, data = small)

plot(fit_1)

summary(fit_1)

hist(sqrt(small$lost_revenue_total))

names(afta_covid_2)

mean(small$laid_off_staff)
mean(small$laid_off_artists_amt, na.rm = T)

stan_wfl <- workflow() %>%
  add_model(linear_reg() %>%
              set_engine("stan") %>%
              set_mode("regression")) %>%
  add_recipe(recipe(lost_revenue_total ~ lost_attendees, data = small))

stan_metrics <- stan_wfl %>%
  fit_resampa

names(small)
```

```{r}
# Time to do some model building! 

# Setting seed and splitting into test and train

set.seed(10)
small_split <- initial_split(small, prop = 0.8)
small_train <- training(small_split)
small_test <- testing(small_split)
small_folds <- vfold_cv(small_train, v = 10)

# Fitting the simplest possible model: lost revenue vs. lost attendees on the training set

lm_wfl_simple <- workflow() %>% 
  add_model(linear_reg() %>%
            set_engine("lm") %>%
            set_mode("regression")) %>% 
  add_recipe(recipe(lost_revenue_total ~  lost_attendees,
                    data = small_train))

lm_wfl_medium <- workflow() %>% 
  add_model(linear_reg() %>%
            set_engine("lm") %>%
            set_mode("regression")) %>% 
  add_recipe(recipe(lost_revenue_total ~  lost_attendees + purpose,
                    data = small_train) %>%
               step_dummy(all_nominal()))

# Fitting a more complex model with additional predictors

lm_wfl_complex <- workflow() %>% 
  add_model(linear_reg() %>%
            set_engine("lm") %>%
            set_mode("regression")) %>% 
  add_recipe(recipe(lost_revenue_total ~  lost_attendees + cancelled_events + new_expenditures_amt + business_closure + purpose,
                    data = small_train) %>%
               step_dummy(all_nominal()))


lm_metrics_simple <- lm_wfl_simple %>%
  fit_resamples(resamples = small_folds) %>%
  collect_metrics()

lm_metrics_medium <- lm_wfl_medium %>%
  fit_resamples(resamples = small_folds) %>%
  collect_metrics()

lm_metrics_complex <- lm_wfl_complex %>%
  fit_resamples(resamples = small_folds) %>%
  collect_metrics()

# Doing it all again with stan instead of a normal linear model

stan_wfl_simple <- workflow() %>% 
  add_model(linear_reg() %>%
            set_engine("stan") %>%
            set_mode("regression")) %>% 
  add_recipe(recipe(lost_revenue_total ~  lost_attendees,
                    data = small_train))

stan_wfl_medium <- workflow() %>% 
  add_model(linear_reg() %>%
            set_engine("stan") %>%
            set_mode("regression")) %>% 
  add_recipe(recipe(lost_revenue_total ~  lost_attendees + purpose,
                    data = small_train) %>%
               step_dummy(all_nominal()))

# Fitting a more complex model with additional predictors

stan_wfl_complex <- workflow() %>% 
  add_model(linear_reg() %>%
            set_engine("stan") %>%
            set_mode("regression")) %>% 
  add_recipe(recipe(lost_revenue_total ~  lost_attendees + cancelled_events + new_expenditures_amt + business_closure + purpose,
                    data = small_train) %>%
               step_dummy(all_nominal()))


stan_metrics_simple <- lm_wfl_simple %>%
  fit_resamples(resamples = small_folds) %>%
  collect_metrics()

stan_metrics_medium <- lm_wfl_medium %>%
  fit_resamples(resamples = small_folds) %>%
  collect_metrics()

stan_metrics_complex <- lm_wfl_complex %>%
  fit_resamples(resamples = small_folds) %>%
  collect_metrics()

model_comparison <- tibble(model = rep(c("Simple Linear Model", "Medium Linear Model",
                     "Complex Linear Model"), each = 2)) %>%
  bind_cols(bind_rows(lm_metrics_simple, lm_metrics_medium, 
                      lm_metrics_complex)) %>%
  filter(.metric ==  "rmse") %>%
  select(model, mean, std_err) %>%
  rename(Model = model, "Mean RMSE" = mean, "Standard Error" = std_err)  %>%
  gt()

library(webshot)

saveRDS(model_comparison, "model_comparison.RDS")

model_comparison

# Seems like the simple model is the best

model_vars <- tibble(name = c("lost_attendees",
                              "cancelled_events", "new_expenditures_amt", "business_closure"," purpose"),
                     description = c("Total number of people/attendees expected to attend all events that have been canceled", "Indicator of whether an organization had canceled events due to COVID-19", "Estimation of the total amount ofunanticipated expenditures that made as a result of the coronavirus", "Indicator of whether business closure was a major
                                     financial concern for the organziation", "Organizational purpose (performing arts, museum/gallery, etc.)"),
                     type = c("numeric, dummy, numeric, dummy, factor"),
                     simple = c("Yes", "No", "No", "No", "No"),
                     medium = c("Yes", "No", "No", "No", "Yes"),
                     complex = c("Yes", "Yes", "Yes", "Yes", "Yes")) %>%
  rename("Variable name" = name, "Description" = description,
         "Variable Type" = type, "In Simple Model?" = simple,
         "In Medium Model?" = medium, "In Complex Model?" = complex)

saveRDS(model_vars, "model_vars.RDS")
```


```{r}
# Now I'll fit on the train to calculate our future RMSE

lm_wfl_simple %>%
  fit(data = small_train) %>%
  predict(new_data = small_test) %>%
  bind_cols(small_test %>% select(lost_revenue_total)) %>%
  metrics(truth = lost_revenue_total, estimate = .pred)

# Refitting the model on the full dataset

model_final <- stan_glm(lost_revenue_total ~  lost_attendees, data = small, refresh = 0)

saveRDS(model_final, "model_final.RDS")

library(broom.mixed)
library(gtsummary)

model_final %>%
  gt()


  tbl_regression(model_final, intercept = TRUE) %>%
  as_gt()
  
  table<- tbl_regression(model_final, intercept = TRUE) %>%
            as_gt()
  
  class(table)
  class(model_comparison)
```


```{r}
# Time to make some graphs to show off what our predictive model can do! 

new_obs <- tibble(lost_attendees = 10000)

individual <- posterior_predict(model_final, newdata = new_obs) %>%
  as_tibble() %>%
  rename("Individual Predictions" = `1`) %>%
  mutate_all(as.numeric)
average <- posterior_epred(model_final, newdata = new_obs) %>%
  as_tibble() %>%
  rename("Average Predictions" = `1`) %>%
  mutate_all(as.numeric)

model_predictions <- cbind(individual, average) %>%
  pivot_longer(cols = everything(), names_to = "Type", values_to = "lost_rev") 


  ggplot(model_predictions, aes(x = lost_rev, fill = Type)) +
  geom_histogram(bins = 50, alpha = 0.7, color = "plum4",
                 position = "identity",
                 aes(y = after_stat(count/sum(count)))) +
  scale_x_continuous(labels = scales::dollar_format()) +
  scale_y_continuous(labels = scales::percent_format())+
  labs(title = "Predictions") +
  scale_fill_manual(values = cute_pal) + 
  theme_bw() +
  labs(title = "Posterior Probability Distribution",
       subtitle = "Making individual and average predictions using our chosen model", x = "Predicted Lost Revenue", y = "Probability")

```


```{r}
# Setting up graphs to make predictions 


```

